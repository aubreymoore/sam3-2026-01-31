{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19397fe",
   "metadata": {},
   "source": [
    "# sam3-2026-01-31.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9992ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv add ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a4d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.sam import SAM3SemanticPredictor\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import exif\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from time import sleep\n",
    "\n",
    "import shapely\n",
    "from shapely.geometry import Polygon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a035281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_poly_from_array_to_wkt(poly: np.array) -> str:\n",
    "    return Polygon(poly).wkt\n",
    "\n",
    "# # Usage example:\n",
    "\n",
    "# poly_wkt = 'POLYGON((0 0, 0 40, 40 40, 40 0, 0 0))'\n",
    "# poly = conv_poly_from_wkt_to_array(poly_wkt)\n",
    "# ic(conv_poly_from_array_to_wkt(poly));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eea5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_poly_from_wkt_to_array(poly_wkt: str) -> np.array:\n",
    "    return np.array(shapely.from_wkt(poly_wkt).exterior.coords)\n",
    "\n",
    "# # Usage example:\n",
    "\n",
    "# poly_wkt = 'POLYGON((0 0, 0 40, 40 40, 40 0, 0 0))'\n",
    "# ic(conv_poly_from_wkt_to_array(poly_wkt));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54f0e74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aubrey/Desktop/sam3-2026-01-31/.venv/lib/python3.13/site-packages/torch/__init__.py:1146: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n",
      "/tmp/ipykernel_1015675/4068954168.py:19: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  elif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n"
     ]
    }
   ],
   "source": [
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" Ã— \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s â†’ %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\tprint(\"Total size:\", total_size)\n",
    " \n",
    "# Usage example:\n",
    " \n",
    "dump_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20106d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu():\n",
    "    \"\"\" \n",
    "    Checks for GPU availability and prints CUDA version and GPU device name if available.\n",
    "    Returns True if GPU is available, otherwise False.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU device name: {torch.cuda.get_device_name(0)}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"No GPU available.\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5dae28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_gpu_tensors():\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            # Check if object is a tensor and on a GPU\n",
    "            if torch.is_tensor(obj) and obj.is_cuda:\n",
    "                print(f\"Type: {type(obj).__name__:20} | Shape: {tuple(obj.shape)!s:20} | Device: {obj.device}\")\n",
    "            # Also check for tensors hidden inside objects (like model parameters)\n",
    "            elif hasattr(obj, 'data') and torch.is_tensor(obj.data) and obj.data.is_cuda:\n",
    "                 print(f\"Type: {type(obj).__name__:20} | Shape: {tuple(obj.data.shape)!s:20} | Device: {obj.data.device}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# list_gpu_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c09e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_results_from_gpu_memory():\n",
    "    \"\"\"\n",
    "    Explicitly manages memory after processing each image to prevent running out of GPU memory\n",
    "    \"\"\"\n",
    "    global results_gpu\n",
    "    del results_gpu \n",
    "    gc.collect() \n",
    "    torch.cuda.empty_cache() # Clears unoccupied cached memory\n",
    "\n",
    "# Usage example:\n",
    "    \n",
    "# delete_results_from_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873f781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sam3_semantic_predictor(input_image_path, text_prompts):\n",
    "    # Initialize predictor with configuration\n",
    "    overrides = dict(\n",
    "        conf=0.25,\n",
    "        task=\"segment\",\n",
    "        mode=\"predict\",\n",
    "        model=\"sam3.pt\",\n",
    "        half=True,  # Use FP16 for faster inference\n",
    "        save=True,  # Save image visualizing output results\n",
    "        save_txt=False,  # Save output results in text format\n",
    "        save_conf=False,  # Save confidence scores   \n",
    "        imgsz=1932,  # Adjusted image size from 1920 to meet stride 14 requirement\n",
    "        batch=1,\n",
    "        device=\"0\",  # Use GPU device 0\n",
    "    )\n",
    "    predictor = SAM3SemanticPredictor(overrides=overrides)\n",
    "\n",
    "    # Set image once for multiple queries\n",
    "    predictor.set_image(input_image_path)\n",
    "\n",
    "    # Query with multiple text prompts\n",
    "    results = predictor(text=text_prompts)\n",
    "\n",
    "    # Visualize and save objects\n",
    "    # visualize_objects(results)\n",
    "    return results\n",
    "\n",
    "# # Example usage:\n",
    "\n",
    "# root_dir = \"/home/aubrey/Desktop/sam3-2026-01-31\"\n",
    "# image_paths = [\"20251129_152106.jpg\", \"08hs-palms-03-zglw-superJumbo.webp\"]\n",
    "# text_prompts = [\"coconut palm tree\"]\n",
    "\n",
    "# os.chdir(root_dir) # ensure we start in the correct directory\n",
    "# for image_path in image_paths:\n",
    "#     results_gpu = run_sam3_semantic_predictor(image_path, text_prompts)\n",
    "   \n",
    "#     # Free up GPU memory in preparation for detecting objects in the next image\n",
    "#     # This is a work-around to prevent out-of-memory errors from the GPU\n",
    "#     # I move all results for further processing and use the GPU only for object detection.\n",
    "#     print('deleting results from GPU memory')       \n",
    "#     results_cpu = [r.cpu() for r in results_gpu] # copy results to CPU\n",
    "#     delete_results_from_gpu_memory()\n",
    "    \n",
    "# print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42efa04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are used for building a SQLite database of images and their detected objects\n",
    "\n",
    "def update_images_table(image_path, db_path):\n",
    "    \"\"\" \n",
    "    Saves data for a single image into an 'images' table in a SQLite database. \n",
    "    If the image contains embedded EXIF metadata, GIS coordinates are extracted and saved. and saves it in a SQLite database.\n",
    "    If the database exists, one record is appended. Otherwise, a new database is created before adding the record.\n",
    "     \n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        db_path (str): Path to the SQLite database file.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    with open(image_path, 'rb') as f:\n",
    "        imgx = exif.Image(f)\n",
    "        \n",
    "    if imgx.has_exif:\n",
    "                \n",
    "        # to see all available exif_data  use imgx.get_all()\n",
    "        \n",
    "        exif_data = {\n",
    "            'image_path': image_path,\n",
    "            'image_width': imgx.image_width,\n",
    "            'image_height': imgx.image_height,\n",
    "            'timestamp': imgx.datetime\n",
    "        }\n",
    "\n",
    "        d, m, s = imgx.gps_latitude\n",
    "        latitude = d + m/60 + s/3600   \n",
    "        if imgx.gps_latitude_ref == 'S':\n",
    "            latitude = -latitude  \n",
    "        exif_data['latitude']  = latitude   \n",
    "\n",
    "        d, m, s = imgx.gps_longitude\n",
    "        longitude = d + m/60 + s/3600   \n",
    "        if imgx.gps_longitude_ref == 'W':\n",
    "            longitude = -longitude\n",
    "        exif_data['longitude'] = longitude\n",
    "    else:\n",
    "        exif_data = {\n",
    "            'image_path': image_path,\n",
    "            'image_width': None,\n",
    "            'image_height': None,\n",
    "            'timestamp': None,\n",
    "            'latitude': None,\n",
    "            'longitude': None\n",
    "        }\n",
    "    df_image = pd.DataFrame([exif_data])\n",
    "    \n",
    "    # Connect to the SQLite database (creates if it doesn't exist)\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    # cursor = conn.cursor()\n",
    "    df_image.to_sql(name='images', con=conn, if_exists='append', index=False)\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def update_detections_table(results, image_path, db_path):\n",
    "    \n",
    "    # Process detection results (assuming one image for simplicity: results[0])\n",
    "    result = results[0]\n",
    "\n",
    "    # --- Extract Bounding Box Data into a DataFrame ---\n",
    "    # The .boxes.data attribute is a tensor containing [x_min, y_min, x_max, y_max, confidence, class]\n",
    "    boxes_data = result.boxes.data.tolist()\n",
    "    df_boxes = pd.DataFrame(boxes_data, columns=['x_min', 'y_min', 'x_max', 'y_max', 'confidence', 'class_id'])\n",
    "\n",
    "    # Add class names for readability\n",
    "    # class_names = model.names\n",
    "    # df_boxes['class_name'] = df_boxes['class_id'].apply(lambda x: class_names[int(x)])\n",
    "\n",
    "    # --- Extract Segmentation Mask Data ---\n",
    "    # Masks are more complex as they represent pixel-wise information or polygon points.\n",
    "    # To put this into a DataFrame, you could store the polygon points list for each object.\n",
    "    masks_data = []\n",
    "    # Iterate over each detected object's mask\n",
    "    for i, mask in enumerate(result.masks.xy):\n",
    "        # mask.xy contains the polygon points as a list of [x, y] coordinates\n",
    "        # You can associate this with the corresponding entry in the bounding box DataFrame\n",
    "        \n",
    "        \n",
    "        # polygon_points = mask.tolist()\n",
    "        # polygon_points_str = ','.join(str(x) for x in polygon_points)\n",
    "        \n",
    "        poly_arr = mask\n",
    "        poly_wkt = conv_poly_from_array_to_wkt(poly_arr)\n",
    "        \n",
    "        masks_data.append({\n",
    "            'image_path': image_path,\n",
    "            'object_index': i, \n",
    "            'class_id': df_boxes.iloc[i]['class_id'], \n",
    "            'poly_wkt': poly_wkt})\n",
    "        df_masks = pd.DataFrame(masks_data)  \n",
    "        \n",
    "    # merge df_masks and df_detections  \n",
    "    df_detections = pd.merge(df_masks, df_boxes, how=\"outer\", left_index=True, right_index=True)\n",
    "    \n",
    "    # Connect to the SQLite database (creates if it doesn't exist)\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    # cursor = conn.cursor()\n",
    "    df_detections.to_sql(name='detections', con=conn, if_exists='append', index=False)\n",
    "    conn.close()\n",
    "    \n",
    "\n",
    "def build_database(image_path, results, db_path):\n",
    "    \"\"\" \n",
    "    Builds a SQLite database with 'images' and 'detections' tables from a list of image paths.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to an image file.\n",
    "        results (list): List of detection results from model.\n",
    "        db_path (str): Path to the SQLite3 database file.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    update_images_table(image_path, db_path)\n",
    "    update_detections_table(results, image_path, db_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b2a657",
   "metadata": {},
   "source": [
    "# MAIN CODE BLOCK\n",
    "Runs only if GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8714431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 12.8\n",
      "GPU device name: NVIDIA GeForce RTX 3080 Laptop GPU\n",
      "Ultralytics 8.4.9 ðŸš€ Python-3.13.11 torch-2.10.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 15992MiB)\n",
      "\n",
      "image 1/1 /home/aubrey/Desktop/sam3-2026-01-31/20251129_152106.jpg: 1932x1932 25 coconut palm trees, 1242.1ms\n",
      "Speed: 12.5ms preprocess, 1242.1ms inference, 5.0ms postprocess per image at shape (1, 3, 1932, 1932)\n",
      "Results saved to \u001b[1m/home/aubrey/Desktop/blog2026/runs/segment/predict52\u001b[0m\n",
      "deleting results from GPU memory\n",
      "building database\n",
      "Ultralytics 8.4.9 ðŸš€ Python-3.13.11 torch-2.10.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 15992MiB)\n",
      "\n",
      "image 1/1 /home/aubrey/Desktop/sam3-2026-01-31/08hs-palms-03-zglw-superJumbo.webp: 1932x1932 2 coconut palm trees, 1135.6ms\n",
      "Speed: 13.5ms preprocess, 1135.6ms inference, 1.0ms postprocess per image at shape (1, 3, 1932, 1932)\n",
      "Results saved to \u001b[1m/home/aubrey/Desktop/blog2026/runs/segment/predict53\u001b[0m\n",
      "deleting results from GPU memory\n",
      "building database\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/home/aubrey/Desktop/sam3-2026-01-31\"\n",
    "image_paths = [\"20251129_152106.jpg\", \"08hs-palms-03-zglw-superJumbo.webp\" ]\n",
    "text_prompts=[\"coconut palm tree\"]\n",
    "db_path = \"sam3_detections.sqlite3\"\n",
    "\n",
    "os.chdir(root_dir) # ensure we start in the correct directory\n",
    "if os.path.exists(db_path):\n",
    "    os.remove(db_path) # Remove existing database to start fresh\n",
    "\n",
    "if check_gpu(): # Only run if GPU is available       \n",
    "    for image_path in image_paths:\n",
    "        results_gpu = run_sam3_semantic_predictor(\n",
    "            input_image_path=image_path,\n",
    "            text_prompts=text_prompts\n",
    "        )\n",
    "        \n",
    "        # Free up GPU memory in preparation for detecting objects in the next image\n",
    "        # This is a work-around to prevent out-of-memory errors from the GPU\n",
    "        # I move all results for further processing and use the GPU only for object detection.\n",
    "        results_cpu = [r.cpu() for r in results_gpu] # copy results to CPU\n",
    "        print('deleting results from GPU memory')       \n",
    "        delete_results_from_gpu_memory() # Clear GPU memory after processing each image\n",
    "        \n",
    "        print('building database') \n",
    "        build_database(\n",
    "            image_path=image_path,\n",
    "            results=results_cpu,                             \n",
    "            db_path=db_path\n",
    "        ) \n",
    " \n",
    "print('FINISHED')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam3-2026-01-31",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
